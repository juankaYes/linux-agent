![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)

# ğŸ§ Linux-Agent (Linu-Agent)

An **offline Linux troubleshooting agent** built using **LangChain**, **LangGraph**, and **Ollama** with **open-source LLMs**.

This project helps users **understand, debug, and fix Linux issues** through a **multi-agent system** that preserves conversational context.

---

## ğŸ§  What is Linux-Agent?

Linux-Agent acts like a **Linux support team** working together:

- One agent improves and clarifies the userâ€™s question
- One agent decides how the system should respond
- One agent specializes in Linux troubleshooting

All processing happens **locally and offline** using **Ollama**.

---

## âœ¨ Features

- Fully **offline** (open-source models via Ollama)
- **Multi-agent architecture** using LangGraph
- **Conversation memory** across turns
- Linux-focused troubleshooting
- Modular and extensible design

---

## ğŸ§± Architecture

The system follows a **managerâ€“specialist flow**:

User
â†“
Orchestration Agent
â†“
Prompt Refining Agent
â†“
Linux Agent


**Analogy:**  
- Orchestration Agent â†’ Decides the next step  
- Prompt Refining Agent â†’ Clarifies the problem  
- Linux Agent â†’ Solves the Linux issue  

---

## ğŸ¤– Agents

### Orchestration Agent
- Controls conversation flow
- Routes tasks between agents
- Maintains state and context

### Prompt Refining Agent
- Refines vague or unclear user input
- Produces structured, actionable prompts

### Linux Agent
- Linux troubleshooting expert
- Handles commands, errors, logs, and system issues

---

## ğŸ’¬ Conversation Memory

The agent keeps track of previous messages, allowing:
- Natural follow-up questions
- Step-by-step debugging
- Context-aware responses

---

## ğŸ—‚ Project Structure
'''text
src/
â”œâ”€â”€ agents/
â”‚ â”œâ”€â”€ orchestration_agent.py
â”‚ â”œâ”€â”€ prompt_refining_agent.py
â”‚ â””â”€â”€ linux_agent.py
â”œâ”€â”€ chains/
â”‚ â””â”€â”€ agent_chains.py
â”œâ”€â”€ commands/
â”‚ â”œâ”€â”€ info.py
â”‚ â””â”€â”€ utils.py
â”œâ”€â”€ common/
â”‚ â”œâ”€â”€ messages/
â”‚ â”‚ â””â”€â”€ terminal_messages.py
â”‚ â””â”€â”€ system_information.py
â”œâ”€â”€ graph/
â”‚ â””â”€â”€ linux_assistant.py
â”œâ”€â”€ llm_models/
â”‚ â”œâ”€â”€ factory.py
â”‚ â”œâ”€â”€ enums.py
â”‚ â””â”€â”€ info.py
â”œâ”€â”€ my_logging/
â”‚ â””â”€â”€ config.py
â”œâ”€â”€ prompts/
â”œâ”€â”€ main.py


---

## ğŸ§ª Tech Stack

![Python](https://img.shields.io/badge/Python-3.x-blue)
![LangChain](https://img.shields.io/badge/LangChain-powered-green)
![LangGraph](https://img.shields.io/badge/LangGraph-enabled-purple)
![Ollama](https://img.shields.io/badge/Ollama-offline-orange)
- Open-source LLMs (offline)

---

## ğŸš€ Getting Started

### Install dependencies
```bash
pip install -r requirements.txt
